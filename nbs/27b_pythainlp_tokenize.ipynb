{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "27b_pythainlp_tokenize.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPZNh8vJPm0TPYn4cIY6e6u"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hroev-q_1koR",
        "colab_type": "text"
      },
      "source": [
        "เนื่องจากภาษาไทย เป็นภาษาที่เขียนติดกันหมด ไม่มีการเว้นคำด้วย Space เหมือนภาษาอังกฤษ ทำให้การตัดคำภาษาไทย หรือ Tokenization มีความซับซ้อน และ การตัดคำที่ถูกต้องมีความสำคัญ ต่อการนำข้อมูลคำศัพท์ ไปประมวลผลต่อ เช่น Feed เข้าโมเดล Machine Learning ต่อไป"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CzApwnjVlKxC"
      },
      "source": [
        "# 0. Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0WcUkQRak7e6",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MGOPzh9vCLJh"
      },
      "source": [
        "Install Library ที่จำเป็น แล้ว Restart Runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJyPgTMyBHHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "239b2525-bbec-47ae-8d5c-ac68ee55e986"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpAhcT3WxGqF",
        "colab_type": "code",
        "outputId": "3174e723-5bfc-4f5c-eb34-55981e988916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# dev version\n",
        "# !pip install https://github.com/PyThaiNLP/pythainlp/archive/dev.zip\n",
        "\n",
        "# release version \n",
        "! pip install pythainlp\n",
        "\n",
        "!pip install epitran\n",
        "!pip install sklearn_crfsuite\n",
        "!pip install tensorflow deepcut\n",
        "!pip install attacut"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.6/dist-packages (2.1.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /tensorflow-2.1.0/python3.6 (from pythainlp) (2.22.0)\n",
            "Requirement already satisfied: dill>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (0.3.1.1)\n",
            "Requirement already satisfied: tinydb>=3.0 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (3.15.2)\n",
            "Requirement already satisfied: nltk>=3.3 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (3.4.5)\n",
            "Requirement already satisfied: tqdm>=4.1 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (4.42.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests>=2.22.0->pythainlp) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests>=2.22.0->pythainlp) (2019.11.28)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests>=2.22.0->pythainlp) (1.25.7)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests>=2.22.0->pythainlp) (3.0.4)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from nltk>=3.3->pythainlp) (1.14.0)\n",
            "Requirement already satisfied: epitran in /usr/local/lib/python3.6/dist-packages (1.8)\n",
            "Requirement already satisfied: setuptools in /tensorflow-2.1.0/python3.6 (from epitran) (45.0.0)\n",
            "Requirement already satisfied: panphon>=0.16 in /usr/local/lib/python3.6/dist-packages (from epitran) (0.17)\n",
            "Requirement already satisfied: marisa-trie in /usr/local/lib/python3.6/dist-packages (from epitran) (0.7.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from epitran) (2019.12.20)\n",
            "Requirement already satisfied: unicodecsv in /usr/local/lib/python3.6/dist-packages (from epitran) (0.14.1)\n",
            "Requirement already satisfied: munkres in /usr/local/lib/python3.6/dist-packages (from panphon>=0.16->epitran) (1.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from panphon>=0.16->epitran) (5.3)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from panphon>=0.16->epitran) (1.18.1)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from panphon>=0.16->epitran) (0.5.3)\n",
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from sklearn_crfsuite) (1.14.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.42.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.9.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.6)\n",
            "Requirement already satisfied: tensorflow in /tensorflow-2.1.0/python3.6 (2.1.0)\n",
            "Requirement already satisfied: deepcut in /usr/local/lib/python3.6/dist-packages (0.7.0.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (3.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /tensorflow-2.1.0/python3.6 (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied: six>=1.12.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /tensorflow-2.1.0/python3.6 (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.26.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /tensorflow-2.1.0/python3.6 (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /tensorflow-2.1.0/python3.6 (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.18.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from deepcut) (0.22.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from deepcut) (0.25.3)\n",
            "Requirement already satisfied: h5py in /tensorflow-2.1.0/python3.6 (from deepcut) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /tensorflow-2.1.0/python3.6 (from protobuf>=3.8.0->tensorflow) (45.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->deepcut) (0.14.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->deepcut) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->deepcut) (2.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /tensorflow-2.1.0/python3.6 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /tensorflow-2.1.0/python3.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /tensorflow-2.1.0/python3.6 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: attacut in /usr/local/lib/python3.6/dist-packages (1.0.6)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /tensorflow-2.1.0/python3.6 (from attacut) (1.18.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from attacut) (0.6.2)\n",
            "Requirement already satisfied: nptyping>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from attacut) (0.3.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /tensorflow-2.1.0/python3.6 (from attacut) (1.14.0)\n",
            "Requirement already satisfied: ssg>=0.0.4 in /usr/local/lib/python3.6/dist-packages (from attacut) (0.0.6)\n",
            "Requirement already satisfied: pyyaml>=5.1.2 in /usr/local/lib/python3.6/dist-packages (from attacut) (5.3)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from attacut) (1.3.1)\n",
            "Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from attacut) (0.2.1)\n",
            "Requirement already satisfied: typish in /usr/local/lib/python3.6/dist-packages (from nptyping>=0.2.0->attacut) (1.3.1)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.6/dist-packages (from ssg>=0.0.4->attacut) (4.42.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from ssg>=0.0.4->attacut) (0.9.6)\n",
            "Requirement already satisfied: termcolor in /tensorflow-2.1.0/python3.6 (from fire>=0.1.3->attacut) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u3BdH34_hN1",
        "colab_type": "text"
      },
      "source": [
        "Restart Runtime เพื่อให้ใช้ Library เวอร์ชัน ที่เพิ่ง Install ลงไป"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86CaxdqnE0Ag",
        "colab_type": "text"
      },
      "source": [
        "ในเคสนี้ เราจะปิด Warning ไว้ก่อน จะได้อ่านผลลัพท์ง่าย"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rha7sfRokmVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3VxLNfAElR29"
      },
      "source": [
        "# 1. Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nGm02SG0CQrq"
      },
      "source": [
        "Import Library ที่จะใช้ ในที่นี้คือ PyThaiNLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUurvnGIsEWv",
        "colab_type": "code",
        "outputId": "23e59bd3-f1b5-439f-8e66-16a3f8fe267c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pythainlp\n",
        "\n",
        "pythainlp.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeJuPfAjSGnt",
        "colab_type": "text"
      },
      "source": [
        "# 2. PyThaiNLP ตัดคำภาษาไทย"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wv5jznJ84lZ",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 word_tokenize ตัดคำ Word, Sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMMqgQz_4sHr",
        "colab_type": "text"
      },
      "source": [
        "ฟังก์ชันตัดคำของ PyThaiNLP ถูกออกแบบมาให้รองรับหลายอัลกอริทึม เช่น \n",
        "\n",
        "* newmm - Dictionary-based Thai Word Segmentation using maximal matching algorithm and Thai Character Cluster (TCC). The code is based on the notebooks created by Korakot Chaovavanich.\n",
        "* longest - Dictionary-based longest-matching Thai word segmentation. Implementation based on the code from Patorn Utenpattanun.\n",
        "* multi_cut - Multi cut – Thai word segmentation with maximum matching. The original source code is from Korakot Chaovavanich.\n",
        "* pyicu - Wrapper for PyICU word segmentation. This wrapper module uses icu.BreakIterator with Thai as icu.Local to locate boundaries between words from the text.\n",
        "* deepcut - Wrapper for deepcut Thai word segmentation. deepcut is a Thai word segmentation library using Deep Neural, specifically, 1D Convolution Neural Network.\n",
        "* attacut - Wrapper for AttaCut - Fast and Reasonably Accurate Word Tokenizer for Thai by Pattarawat Chormai\n",
        "* tcc - The implementation of tokenizer accorinding to Thai Character Clusters (TCCs) rules purposed by Theeramunkong et al. 2000.\n",
        "* etcc - Enhanced Thai Character Cluster (ETCC) Python implementation by Wannaphong Phatthiyaphaibun (19 June 2017)\n",
        "\n",
        "โดยอัลกอริทึมใหม่ล่าสุด และเป็น Default ของ PyThaiNLP tokenize ณ ขณะนี้ คือ newmm ที่ใช้ อัลกอริทึม หา maximum matching จากใน Dictionary ที่ทำงานได้อย่างรวดเร็ว และถูกต้องพอสมควร"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbViFYbf6rzl",
        "colab_type": "text"
      },
      "source": [
        "เราจะ Import sent_tokenize ที่ตัดคำจาก Space, Full stop, New line เหมือนที่ใช้ในภาษาอังกฤษ และ word_tokenize พระเอกของเรา ฟังก์ชันตัดคำภาษาไทย"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTbxnjo4dj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp import sent_tokenize, word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "324GpTe-7J_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"เมืองเชียงรายมีประวัติศาสตร์อันยาวนาน        เป็นที่ตั้งของหิรัญนครเงินยางเชียงแสน\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqEqLApI7KNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "190f0331-187e-40d5-a7db-b52f22fc495a"
      },
      "source": [
        "print(\"sent_tokenize:\", sent_tokenize(text))\n",
        "print(\"word_tokenize:\", word_tokenize(text))\n",
        "print(\"no whitespace:\", word_tokenize(text, keep_whitespace=False))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sent_tokenize: ['เมืองเชียงรายมีประวัติศาสตร์อันยาวนาน', 'เป็นที่ตั้งของหิรัญนครเงินยางเชียงแสน']\n",
            "word_tokenize: ['เมือง', 'เชียงราย', 'มี', 'ประวัติศาสตร์', 'อัน', 'ยาวนาน', '        ', 'เป็นที่ตั้ง', 'ของ', 'หิรัญ', 'นคร', 'เงิน', 'ยาง', 'เชียงแสน']\n",
            "no whitespace: ['เมือง', 'เชียงราย', 'มี', 'ประวัติศาสตร์', 'อัน', 'ยาวนาน', 'เป็นที่ตั้ง', 'ของ', 'หิรัญ', 'นคร', 'เงิน', 'ยาง', 'เชียงแสน']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8iIx0mM7Kas",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 เปรียบเทียบตัดคำภาษาไทย ด้วยอัลกอริทึมต่าง ๆ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYm_YkkX7Kyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"งานเทศกาลลิ้นจี่และของดีเมืองเชียงราย เทศกาลที่ชาวเกษตรกรต่างนำผลผลิตทางการเกษตรของตนมาออกร้าน โดยเฉพาะลิ้นจี่ที่มีชื่อเสียงมากของเชียงราย \""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8Cx6qz-9pHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "9362e7d3-7003-4d4b-a71d-6c1145c537d0"
      },
      "source": [
        "print(\"newmm    :\", word_tokenize(text))  # default engine is \"newmm\"\n",
        "print(\"longest  :\", word_tokenize(text, engine=\"longest\"))\n",
        "print(\"multi_cut:\", word_tokenize(text, engine=\"multi_cut\"))\n",
        "print(\"pyicu    :\", word_tokenize(text, engine=\"pyicu\"))\n",
        "print(\"deepcut  :\", word_tokenize(text, engine=\"deepcut\"))\n",
        "print(\"tcc      :\", word_tokenize(text, engine=\"tcc\"))\n",
        "print(\"etcc     :\", word_tokenize(text, engine=\"etcc\"))\n",
        "print(\"ulmfit   :\", word_tokenize(text, engine=\"ulmfit\"))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "newmm    : ['งานเทศกาล', 'ลิ้นจี่', 'และ', 'ของดี', 'เมือง', 'เชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผลผลิต', 'ทาง', 'การเกษตร', 'ของ', 'ตน', 'มา', 'ออกร้าน', ' ', 'โดยเฉพาะ', 'ลิ้นจี่', 'ที่', 'มีชื่อเสียง', 'มาก', 'ของ', 'เชียงราย', ' ']\n",
            "longest  : ['งานเทศกาล', 'ลิ้นจี่', 'และ', 'ของดี', 'เมือง', 'เชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผลผลิต', 'ทางการ', 'เกษตร', 'ของ', 'ตน', 'มา', 'ออกร้าน', ' ', 'โดยเฉพาะ', 'ลิ้นจี่', 'ที่', 'มีชื่อเสียง', 'มาก', 'ของ', 'เชียงราย', ' ']\n",
            "multi_cut: ['งานเทศกาล', 'ลิ้นจี่', 'และ', 'ของดี', 'เมือง', 'เชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผลผลิต', 'ทางการเกษตร', 'ของ', 'ตน', 'มา', 'ออกร้าน', ' ', 'โดยเฉพาะ', 'ลิ้นจี่', 'ที่', 'มีชื่อเสียงมาก', 'ของ', 'เชียงราย', ' ']\n",
            "pyicu    : ['งานเทศกาล', 'ลิ้นจี่', 'และ', 'ของดี', 'เมือง', 'เชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผลผลิต', 'ทาง', 'การเกษตร', 'ของ', 'ตน', 'มา', 'ออกร้าน', ' ', 'โดยเฉพาะ', 'ลิ้นจี่', 'ที่', 'มีชื่อเสียง', 'มาก', 'ของ', 'เชียงราย', ' ']\n",
            "deepcut  : ['งาน', 'เทศกาล', 'ลิ้นจี่', 'และ', 'ของ', 'ดี', 'เมืองเชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผล', 'ผลิต', 'ทาง', 'การ', 'เกษตร', 'ของ', 'ตน', 'มา', 'ออก', 'ร้าน', ' ', 'โดย', 'เฉพาะ', 'ลิ้นจี่', 'ที่', 'มี', 'ชื่อเสียง', 'มาก', 'ของ', 'เชียงราย', ' ']\n",
            "tcc      : ['งานเทศกาล', 'ลิ้นจี่', 'และ', 'ของดี', 'เมือง', 'เชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผลผลิต', 'ทาง', 'การเกษตร', 'ของ', 'ตน', 'มา', 'ออกร้าน', ' ', 'โดยเฉพาะ', 'ลิ้นจี่', 'ที่', 'มีชื่อเสียง', 'มาก', 'ของ', 'เชียงราย', ' ']\n",
            "etcc     : ['งานเทศกาล', 'ลิ้นจี่', 'และ', 'ของดี', 'เมือง', 'เชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผลผลิต', 'ทาง', 'การเกษตร', 'ของ', 'ตน', 'มา', 'ออกร้าน', ' ', 'โดยเฉพาะ', 'ลิ้นจี่', 'ที่', 'มีชื่อเสียง', 'มาก', 'ของ', 'เชียงราย', ' ']\n",
            "ulmfit   : ['งานเทศกาล', 'ลิ้นจี่', 'และ', 'ของดี', 'เมือง', 'เชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผลผลิต', 'ทาง', 'การเกษตร', 'ของ', 'ตน', 'มา', 'ออกร้าน', ' ', 'โดยเฉพาะ', 'ลิ้นจี่', 'ที่', 'มีชื่อเสียง', 'มาก', 'ของ', 'เชียงราย', ' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MAtpZ2N-PRA",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 เพิ่มคำใน Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp3YNqhTHvwr",
        "colab_type": "text"
      },
      "source": [
        "ในกรณีที่ข้อความของเรา มีคำแปลก ๆ ที่ไม่มีใน Dictionary ทั่วไป เราสามารถเพิ่มคำเหล่านั้น เข้าไปใน Dictionary ที่ใช้ตัดคำได้ดังตัวอย่างด้านล่าง \n",
        "\n",
        "หรือเราจะสร้าง Dictionary ของเราเองจาก `set()` ว่าง ตั้งแต่ต้นเลยก็ได้"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMDWRfINFwl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenizer??\n",
        "# thai_words??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3srPNMNDZLt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "940e3c0f-f209-42fc-f6d3-453817d087a7"
      },
      "source": [
        "from pythainlp import word_tokenize, Tokenizer\n",
        "from pythainlp.tokenize import dict_trie\n",
        "from pythainlp.corpus.common import thai_words\n",
        "\n",
        "text = \"เป็งปุ๊ด หรือ เพ็ญพุธ เป็นประเพณีตักบาตรเที่ยงคืนค่อนรุ่งเข้าสู่วันเพ็ญขึ้น15 ค่ำที่ตรงกับวันพุธ ตามวัฒนธรรมและความเชื่อของบรรพบุรุษล้านนาไทย\"\n",
        "\n",
        "print(\"newmm  :\", word_tokenize(text))  # default engine is \"newmm\"\n",
        "print(\"longest:\", word_tokenize(text, engine=\"longest\"))\n",
        "\n",
        "words = [\"เป็งปุ๊ด\", \"เพ็ญพุธ\"]\n",
        "custom_words_list = set(thai_words())\n",
        "## add multiple words\n",
        "custom_words_list.update(words)\n",
        "## add word\n",
        "# custom_words_list.add('เป็งปุ๊ด')\n",
        "# custom_words_list.add('เพ็ญพุธ')\n",
        "trie = dict_trie(dict_source=custom_words_list)\n",
        "\n",
        "custom_tokenizer = Tokenizer(custom_dict=trie, engine='newmm')\n",
        "\n",
        "print(\"custom :\", custom_tokenizer.word_tokenize(text))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "newmm  : ['เป็ง', 'ปุ๊', 'ด', ' ', 'หรือ', ' ', 'เพ็ญ', 'พุธ', ' ', 'เป็น', 'ประเพณี', 'ตักบาตร', 'เที่ยงคืน', 'ค่อน', 'รุ่ง', 'เข้าสู่', 'วันเพ็ญ', 'ขึ้น', '15', ' ', 'ค่ำ', 'ที่', 'ตรง', 'กับ', 'วัน', 'พุธ', ' ', 'ตาม', 'วัฒนธรรม', 'และ', 'ความเชื่อ', 'ของ', 'บรรพบุรุษ', 'ล้านนา', 'ไทย']\n",
            "longest: ['เป็ง', 'ปุ๊', 'ด', ' ', 'หรือ', ' ', 'เพ็ญ', 'พุธ', ' ', 'เป็น', 'ประเพณี', 'ตักบาตร', 'เที่ยงคืน', 'ค่อน', 'รุ่ง', 'เข้าสู่', 'วันเพ็ญ', 'ขึ้น', '15', ' ', 'ค่ำ', 'ที่', 'ตรง', 'กับ', 'วัน', 'พุธ', ' ', 'ตาม', 'วัฒนธรรม', 'และ', 'ความเชื่อ', 'ของ', 'บรรพบุรุษ', 'ล้านนา', 'ไทย']\n",
            "custom : ['เป็งปุ๊ด', ' ', 'หรือ', ' ', 'เพ็ญพุธ', ' ', 'เป็น', 'ประเพณี', 'ตักบาตร', 'เที่ยงคืน', 'ค่อน', 'รุ่ง', 'เข้าสู่', 'วันเพ็ญ', 'ขึ้น', '15', ' ', 'ค่ำ', 'ที่', 'ตรง', 'กับ', 'วัน', 'พุธ', ' ', 'ตาม', 'วัฒนธรรม', 'และ', 'ความเชื่อ', 'ของ', 'บรรพบุรุษ', 'ล้านนา', 'ไทย']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0ZXocFREA-Y",
        "colab_type": "text"
      },
      "source": [
        "## 2.4 Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-mmphOTMVVZ",
        "colab_type": "text"
      },
      "source": [
        "ในการใช้งานจริง ความเร็วในการตัดคำก็เป็นเรื่องสำคัญ ยิ่งถ้าเรามีข้อมูลขนาดใหญ่ Streaming เข้ามา ฟังก์ชันตัดคำเป็นด่านแรกที่ต้องทำงานให้ทัน โดยเฉพาะอย่างยิ่งกับงานที่ Online Real-time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4L2kRMY5Igqr",
        "colab": {}
      },
      "source": [
        "speedtest_text = \"\"\"\n",
        "จังหวัดเชียงใหม่มีประวัติศาสตร์อันยาวนาน เคยเป็นเมืองหลวงของอาณาจักรล้านนาแต่โบราณ มี \"คำเมือง\" \n",
        "เป็นภาษาท้องถิ่น มีเอกลักษณ์เฉพาะตัวทั้งด้านประเพณีวัฒนธรรม และมีแหล่งท่องเที่ยวจำนวนมาก \n",
        "โดยเริ่มวางตัวเป็นนครสร้างสรรค์ และได้รับการประกาศเป็นเมืองสร้างสรรค์ของโลกทางด้านหัตถกรรมและศิลปะพื้นบ้าน\n",
        "เมื่อปี พ.ศ. 2560 ปัจจุบันกำลังพิจารณาสมัครเมืองมรดกโลกจากองค์การยูเนสโก\n",
        "เชียงใหม่ยังถือเป็นศูนย์กลางด้านดาราศาสตร์ของเอเชียตะวันออกเฉียงใต้\n",
        "โดยเป็นที่ตั้งของหอดูดาวแห่งชาติและอุทยานดาราศาสตร์แห่งชาติ\n",
        "\n",
        "จังหวัดเชียงใหม่มีป่าไม้หลายประเภท ประกอบด้วย ป่าดิบเขา ป่าดิบแล้ง ป่าเบญจพรรณ ป่าเต็งรัง \n",
        "และป่าเต็งรังผสมป่าสนเขา และป่าแดง เป็นต้น พื้นที่ป่าไม้ ประกอบด้วย ป่าธรรมชาติ สวนป่า \n",
        "และป่าฟื้นฟูตามธรรมชาติ โดยมีพื้นที่ป่าไม้อยู่ในจังหวัดเชียงใหม่ 12,222,395 ไร่ คิดเป็นร้อยละ 69.93 \n",
        "ของพื้นที่ทั้งจังหวัด แบ่งเป็นป่าสงวนแห่งชาติ จำนวน 25 แห่ง อุทยานแห่งชาติ 14 แห่ง \n",
        "เขตรักษาพันธุ์สัตว์ป่า 4 แห่ง วนอุทยานแห่งชาติ 2 แห่ง และเขตห้ามล่าสัตว์ป่า 1 แห่ง \n",
        "และจังหวัดเชียงใหม่ยังเป็นจังหวัดที่ถือได้ว่ามีพื้นที่เขตเมืองใกล้กับเขตอุทยานแห่งชาติมากที่สุดในประเทศอีกด้วย \n",
        "\n",
        "จังหวัดเชียงใหม่ประกอบด้วยหินตะกอนและหินแปร อายุแก่สุดคือหินยุคพรีแคมเบรียน \n",
        "ไปจนถึงอายุอ่อนคือชั้นตะกอนร่วนในยุคควอเทอร์นารี หินอัคนีประกอบด้วยหินอัคนีแทรกดันในยุคคาร์บอนิเฟอรัส \n",
        "และยุคไทรแอสซิก ส่วนหินอัคนีพุเป็นหินภูเขาไฟยุคดีโวเนียน-คาร์บอนิเฟอรัส \n",
        "และหินภูเขาไฟ ยุคเพอร์เมียน-ไทรแอสซิก\n",
        "\n",
        "จังหวัดเชียงใหม่มีการใช้ประโยชน์จากทรัพยากรธรณี โดยมีการผลิตแร่ที่สำคัญ 8 ชนิด ได้แก่ ถ่านหิน \n",
        "เฟลด์สปาร์ (แร่ฟันม้า) แมงกานีส ชีไลต์ ดีบุก ดินขาว ฟลูออไรด์ และแร่หินอุตสาหกรรม \n",
        "และจังหวัดเชียงใหม่ยังมีแหล่งทรัพยากรธรณีที่สำคัญ เช่น แหล่งปิโตรเลียม อำเภอฝาง \n",
        "สภาพทางธรณีวิทยาที่เป็นแหล่งท่องเที่ยว ได้แก่ บ่อน้ำพุร้อน อำเภอสันกำแพงและอำเภอฝาง โป่งเดือด \n",
        "อำเภอแม่แตง บ่อน้ำแร่ธรรมชาติ อำเภอแม่ริม เป็นต้น\n",
        "\n",
        "จังหวัดเชียงใหม่ตั้งอยู่ในพื้นที่ที่มีโอกาสเกิดแผ่นดินไหว ซึ่งมีรอยเลื่อนมีพลัง 2 แห่งที่พาดผ่านจังหวัด \n",
        "ได้แก่ \"รอยเลื่อนแม่จัน\" ซึ่งตั้งอยู่ทางทิศเหนือของจังหวัด พาดผ่านอำเภอฝางและอำเภอแม่อายในทิศตะวันออก-ตะวันตก \n",
        "และ \"รอยเลื่อนแม่ทา\" พาดผ่านพื้นที่ตอนกลางของจังหวัดในทิศเหนือ-ใต้ ผ่านอำเภอพร้าว ดอยสะเก็ด \n",
        "แม่ออน เชียงดาว แม่แตง แม่ริม สันทราย เมืองเชียงใหม่ สารภี หางดง สันป่าตอง และแม่วาง \n",
        "นอกจากนี้พื้นที่ส่วนอื่นของจังหวัดก็มีโอกาสที่จะได้รับผลกระทบจากแผ่นดินไหวที่เกิดขึ้นในบริเวณอื่นเช่นกัน \n",
        "โดยแผ่นดินไหวที่มีศูนย์กลางในเขตจังหวัดเชียงใหม่ครั้งรุนแรงที่สุดครั้งหนึ่งเกิดขึ้นเมื่อเดือนธันวาคม พ.ศ. 2549 \n",
        "ขนาด 5.1 มีจุดเหนือศูนย์กลางในอำเภอแม่ริม ทำให้เกิดความเสียหายเล็กน้อยในบริเวณอำเภอแม่ริมและอำเภอใกล้เคียง\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W_DuQHPWBH5",
        "colab_type": "text"
      },
      "source": [
        "### Wrapper ฟังก์ชัน word_tokenize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDlW2758Upzz",
        "colab_type": "text"
      },
      "source": [
        "เราจะเรียกใช้อัลกอริทึมต่าง ๆ ผ่าน Wrapper ฟังก์ชัน word_tokenize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxEZmkX5P6rh",
        "colab_type": "text"
      },
      "source": [
        "ulmfit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFEPGbuTONmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21e16c71-a400-4ea2-f7cc-6766d3f92700"
      },
      "source": [
        "%%timeit \n",
        "tokens = word_tokenize(speedtest_text, engine=\"ulmfit\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 6.07 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akTO2WcXP4K4",
        "colab_type": "text"
      },
      "source": [
        "etcc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soi-hB15OLTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bf3f7de-8f7a-43a0-e4c3-23787081d743"
      },
      "source": [
        "%%timeit\n",
        "tokens = word_tokenize(speedtest_text, engine=\"etcc\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 6.4 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zePeatxfP2cV",
        "colab_type": "text"
      },
      "source": [
        "tcc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjG7wh8QOLHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da93f3be-26d1-44d2-da20-e3fa33440f34"
      },
      "source": [
        "%%timeit\n",
        "tokens = word_tokenize(speedtest_text, engine=\"tcc\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 6.45 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZBFx7eTP0Gc",
        "colab_type": "text"
      },
      "source": [
        "deepcut"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt9lh0FaOK7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26edcbce-2ef4-4e97-de2f-c15a138ca778"
      },
      "source": [
        "%%timeit\n",
        "tokens = word_tokenize(speedtest_text, engine=\"deepcut\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 971 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgt-s8c5SjUA",
        "colab_type": "text"
      },
      "source": [
        "attacut"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ7RzjR7Si22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19b71bdb-2f44-4034-ebbd-add9e2fe4576"
      },
      "source": [
        "%%timeit\n",
        "tokens = word_tokenize(speedtest_text, engine=\"attacut\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 72.1 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvTRDmFqPyMa",
        "colab_type": "text"
      },
      "source": [
        "pyicu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whVSeJzzOKtn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b052c548-d9a5-4929-cd24-b8af559ddce1"
      },
      "source": [
        "%%timeit\n",
        "tokens = word_tokenize(speedtest_text, engine=\"pyicu\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 6.29 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC0yCjTmPv-_",
        "colab_type": "text"
      },
      "source": [
        "longest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qMF_0xyOIgqs",
        "outputId": "6827de94-eb2c-454a-edb7-d4af76c39c3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit\n",
        "tokens = word_tokenize(speedtest_text, engine=\"longest\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 1.77 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iwzOO50PuJ2",
        "colab_type": "text"
      },
      "source": [
        "newmm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NlCSHylIIgqv",
        "outputId": "6f3c7120-44e9-44a0-de07-3433416e883d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit\n",
        "tokens = word_tokenize(speedtest_text, engine=\"newmm\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 6.09 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhMQawv1Prmc",
        "colab_type": "text"
      },
      "source": [
        "newmm-safe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8Y-Z98RsEYu",
        "colab_type": "code",
        "outputId": "bda8caca-7bfa-4639-b279-385716314bc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit\n",
        "tokens = word_tokenize(speedtest_text, engine=\"newmm-safe\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 7.31 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXQFfUBoMVyU",
        "colab_type": "text"
      },
      "source": [
        "จะเห็นได้ว่าความเร็วไม่ต่างกันมาก ไม่เกิน 10 Millisecond ยกเว้น attacut ใช้เวลา 100 Millisecond deepcut กับ longest ที่ใช้เวลาหลักวินาที ช้ากว่าถึง 100 เท่า"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgQlf_mpWOZH",
        "colab_type": "text"
      },
      "source": [
        "## Directly call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cSq1TjFU6lx",
        "colab_type": "text"
      },
      "source": [
        "ลองเรียก แบบโดยตรง ไม่ผ่าน Wrapper Function `word_tokenize()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T0FUZuUUTpk",
        "colab_type": "text"
      },
      "source": [
        "newmm แบบเรียกโดยตรง"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SaSlNna8Igqx",
        "outputId": "721105ca-aa0e-4bed-9533-805aa15b283b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit \n",
        "tokens = pythainlp.tokenize.newmm.segment(speedtest_text)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 6.07 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9SYdCgKUgks",
        "colab_type": "text"
      },
      "source": [
        "newmm-safe แบบเรียกโดยตรง"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvyXWTN3sEY0",
        "colab_type": "code",
        "outputId": "6c8be624-c8bf-4fb8-8202-4125e5de5b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit\n",
        "tokens = pythainlp.tokenize.newmm.segment(speedtest_text, safe_mode=True)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 7.34 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW7YCrNLQAEX",
        "colab_type": "text"
      },
      "source": [
        "## 3. All Possible Segments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNt9Qewbag8u",
        "colab_type": "text"
      },
      "source": [
        "ดูความเป็นไปได้ทุกแบบในการตัดคำ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMRYmXRxQAKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.tokenize.multi_cut import find_all_segment, mmcut, segment\n",
        "# text = \"เมืองเชียงรายมีประวัติศาสตร์อันยาวนาน\"\n",
        "text = \"จังหวัดเชียงรายตั้งอยู่ตอนเหนือสุดของประเทศไทย\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enu28peXW8lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mmcut??\n",
        "# segment??\n",
        "# find_all_segment??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-gm6J3-YzIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "60ac1b5c-f889-445a-d260-d33919f47ebc"
      },
      "source": [
        "find_all_segment(text)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['จัง|หวัด|เชียง|ราย|ตั้ง|อยู่|ตอน|เหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จังหวัด|เชียง|ราย|ตั้ง|อยู่|ตอน|เหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียงราย|ตั้ง|อยู่|ตอน|เหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จังหวัด|เชียงราย|ตั้ง|อยู่|ตอน|เหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียง|ราย|ตั้งอยู่|ตอน|เหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จังหวัด|เชียง|ราย|ตั้งอยู่|ตอน|เหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียงราย|ตั้งอยู่|ตอน|เหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จังหวัด|เชียงราย|ตั้งอยู่|ตอน|เหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียง|ราย|ตั้ง|อยู่|ตอนเหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จังหวัด|เชียง|ราย|ตั้ง|อยู่|ตอนเหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียงราย|ตั้ง|อยู่|ตอนเหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จังหวัด|เชียงราย|ตั้ง|อยู่|ตอนเหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียง|ราย|ตั้งอยู่|ตอนเหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จังหวัด|เชียง|ราย|ตั้งอยู่|ตอนเหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียงราย|ตั้งอยู่|ตอนเหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จังหวัด|เชียงราย|ตั้งอยู่|ตอนเหนือ|สุด|ของ|ประ|เทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียง|ราย|ตั้ง|อยู่|ตอน|เหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จังหวัด|เชียง|ราย|ตั้ง|อยู่|ตอน|เหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียงราย|ตั้ง|อยู่|ตอน|เหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จังหวัด|เชียงราย|ตั้ง|อยู่|ตอน|เหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียง|ราย|ตั้งอยู่|ตอน|เหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จังหวัด|เชียง|ราย|ตั้งอยู่|ตอน|เหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียงราย|ตั้งอยู่|ตอน|เหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จังหวัด|เชียงราย|ตั้งอยู่|ตอน|เหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียง|ราย|ตั้ง|อยู่|ตอนเหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จังหวัด|เชียง|ราย|ตั้ง|อยู่|ตอนเหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียงราย|ตั้ง|อยู่|ตอนเหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จังหวัด|เชียงราย|ตั้ง|อยู่|ตอนเหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียง|ราย|ตั้งอยู่|ตอนเหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จังหวัด|เชียง|ราย|ตั้งอยู่|ตอนเหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จัง|หวัด|เชียงราย|ตั้งอยู่|ตอนเหนือ|สุด|ของ|ประเทศ|ไทย|',\n",
              " 'จังหวัด|เชียงราย|ตั้งอยู่|ตอนเหนือ|สุด|ของ|ประเทศ|ไทย|']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8ngVn3zQAPu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58f0436f-d5bc-4e85-83c0-ac2deb7f81f2"
      },
      "source": [
        "mmcut(text)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['จังหวัด', 'เชียงราย', 'ตั้งอยู่', 'ตอนเหนือ', 'สุด', 'ของ', 'ประเทศ', 'ไทย']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHa8VhZsY8jo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bd2ee28-444e-4e02-f63f-4ac5653fb5f7"
      },
      "source": [
        "segment(text)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['จังหวัด', 'เชียงราย', 'ตั้งอยู่', 'ตอนเหนือ', 'สุด', 'ของ', 'ประเทศ', 'ไทย']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmSmE1RzY8aS",
        "colab_type": "text"
      },
      "source": [
        "# 4. Subword Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpBm6JhycZJ9",
        "colab_type": "text"
      },
      "source": [
        "เราสามารถทำ Tokenization ระดับย่อยลงไปกว่า Word ได้อีก เรียกว่า Subword มี 2 วิธีได้แก่ Syllable (พยางค์) และ Thai Character Cluster (TCC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2iNRuOQY8GQ",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 Thai Character Cluster (TCC) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InkQIfUFeM_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp import subword_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRjDZeMHY77v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "beb8a877-ffda-4436-ec45-a7c6b0a9b2a7"
      },
      "source": [
        "text = \"จังหวัดเชียงราย\"\n",
        "\n",
        "subword_tokenize(text)  # default subword unit is TCC"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['จัง', 'ห', 'วัด', 'เชีย', 'ง', 'รา', 'ย']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLbV31QVcGpQ",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 Syllable (พยางค์)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8swrY5hAY8QQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f428840c-9ed3-465b-a01a-ba4cc43880cd"
      },
      "source": [
        "subword_tokenize(text, engine=\"ssg\")  # use ssg for syllable"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['จัง', 'หวัด', 'เชียง', 'ราย']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKDlYeoLef-W",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 Low-level TCC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSU58VLae-18",
        "colab_type": "text"
      },
      "source": [
        "ใช้ Low-level ฟังก์ชัน ของ TCC ในการทำ Pre-processing เช่น ในการเช็คการตัด String เพื่อขึ้นบรรทัดใหม่"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Gyig20XIgq-",
        "outputId": "8e942914-92b2-4b1e-8665-5a1f4b98f7d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pythainlp.tokenize import tcc\n",
        "\n",
        "tcc.segment(text)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['จัง', 'ห', 'วัด', 'เชีย', 'ง', 'รา', 'ย']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjNECQOZfUdB",
        "colab_type": "text"
      },
      "source": [
        "`tcc_pos()` คำนวน ตำแหน่งที่ตัด"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cF-zQJU1IgrA",
        "outputId": "9826267b-bf36-46f9-b428-8b7b5e214df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tcc.tcc_pos(text)  # return positions"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3, 4, 7, 11, 12, 14, 15}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAqGHvXbfWLi",
        "colab_type": "text"
      },
      "source": [
        "tcc() สร้าง Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aL2PiPUvIgrE",
        "outputId": "75b4b779-5932-4078-e47c-f5d7046ea978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for ch in tcc.tcc(text):  # TCC generator\n",
        "    print(ch, end='-')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "จัง-ห-วัด-เชีย-ง-รา-ย-"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWxx8WjoC6Yn",
        "colab_type": "text"
      },
      "source": [
        "# Credit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVATahu8C8G1",
        "colab_type": "text"
      },
      "source": [
        "* https://www.thainlp.org/pythainlp/tutorials/notebooks/pythainlp_get_started.html\n",
        "* https://thainlp.org/pythainlp/docs/2.0/api/tokenize.html\n",
        "* https://github.com/PyThaiNLP/pythainlp\n",
        "* https://www.facebook.com/pythainlp/\n",
        "* https://www.facebook.com/groups/thainlp/\n",
        "* https://www.youtube.com/watch?v=fKM9lTcyXLA\n",
        "* https://th.wikipedia.org/wiki/%E0%B8%88%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A7%E0%B8%B1%E0%B8%94%E0%B9%80%E0%B8%8A%E0%B8%B5%E0%B8%A2%E0%B8%87%E0%B8%A3%E0%B8%B2%E0%B8%A2\n",
        "* https://th.wikipedia.org/wiki/%E0%B8%88%E0%B8%B1%E0%B8%87%E0%B8%AB%E0%B8%A7%E0%B8%B1%E0%B8%94%E0%B9%80%E0%B8%8A%E0%B8%B5%E0%B8%A2%E0%B8%87%E0%B9%83%E0%B8%AB%E0%B8%A1%E0%B9%88\n",
        "* Syllable segmentation is using [`ssg`](https://github.com/ponrawee/ssg), a CRF syllable segmenter for Thai by Ponrawee Prasertsom.\n",
        "* TCC is smaller than syllable. For information about TCC, see [Character Cluster Based Thai Information Retrieval](https://www.researchgate.net/publication/2853284_Character_Cluster_Based_Thai_Information_Retrieval) (Theeramunkong et al. 2004).\n",
        "* https://github.com/PyThaiNLP/attacut\n",
        "* https://github.com/rkcosmos/deepcut\n",
        "* https://github.com/ovalhub/pyicu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5AGZCIrQO8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}